{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y1onB6kUvo4Z"
      },
      "outputs": [],
      "source": [
        "# import libraries (you may add additional imports but you may not have to)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iAQGqqO_vo4d",
        "outputId": "89aa4886-2632-437a-a950-8e8e71658eab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-11 17:23:23--  https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.2.33, 104.26.3.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26085508 (25M) [application/zip]\n",
            "Saving to: â€˜book-crossings.zipâ€™\n",
            "\n",
            "book-crossings.zip  100%[===================>]  24.88M  93.7MB/s    in 0.3s    \n",
            "\n",
            "2023-03-11 17:23:23 (93.7 MB/s) - â€˜book-crossings.zipâ€™ saved [26085508/26085508]\n",
            "\n",
            "Archive:  book-crossings.zip\n",
            "  inflating: BX-Book-Ratings.csv     \n",
            "  inflating: BX-Books.csv            \n",
            "  inflating: BX-Users.csv            \n"
          ]
        }
      ],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
        "\n",
        "!unzip book-crossings.zip\n",
        "\n",
        "books_filename = 'BX-Books.csv'\n",
        "ratings_filename = 'BX-Book-Ratings.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NClILWOiEd6Q"
      },
      "outputs": [],
      "source": [
        "# import csv data into dataframes\n",
        "df_books = pd.read_csv(\n",
        "    books_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "df_ratings = pd.read_csv(\n",
        "    ratings_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAcXjkCFCh0A"
      },
      "outputs": [],
      "source": [
        "# add your code here - consider creating a new cell for each section of code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of users to remove\n",
        "user_ratingCount = (df_ratings.\n",
        "     groupby(by = ['user'])['rating'].\n",
        "     count().\n",
        "     reset_index().\n",
        "     rename(columns = {'rating': 'totalRatingCount'})\n",
        "     [['user', 'totalRatingCount']]\n",
        ")\n",
        "users_to_remove = user_ratingCount.query('totalRatingCount > 200').user.tolist()"
      ],
      "metadata": {
        "id": "fmUNfV3GvDkW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge rating and catalog by bookId\n",
        "df = pd.merge(df_ratings,df_books,on='isbn')\n"
      ],
      "metadata": {
        "id": "ayn3XTnCv3ll"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create totalRatingCount\n",
        "book_ratingCount = (df.\n",
        "     groupby(by = ['title'])['rating'].\n",
        "     count().\n",
        "     reset_index().\n",
        "     rename(columns = {'rating': 'totalRatingCount'})\n",
        "     [['title', 'totalRatingCount']]\n",
        "    )"
      ],
      "metadata": {
        "id": "74OcCug9v7Sb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_with_totalRatingCount = df.merge(book_ratingCount, left_on = 'title', right_on = 'title', how = 'left')\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
      ],
      "metadata": {
        "id": "0TL9xABywAcq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove books with less than 100 ratings\n",
        "rating_popular_movie = rating_with_totalRatingCount.query('totalRatingCount > 100')\n",
        "\n",
        "# remove from the dataset users with less than 200 ratings \n",
        "rating_popular_movie = rating_popular_movie[rating_popular_movie['user'].isin(users_to_remove)]"
      ],
      "metadata": {
        "id": "NKVZpjaHwFn0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicates\n",
        "#rating_popular_movie.drop_duplicates(subset=['title'], keep=False, inplace=True)\n",
        "\n",
        "# pivot table and create matrix\n",
        "book_features_df = rating_popular_movie.pivot_table(index='title',columns='user',values='rating').fillna(0)\n",
        "book_features_df_matrix = csr_matrix(book_features_df.values)"
      ],
      "metadata": {
        "id": "3vvroEvqwJoR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f5ZUd-L1SQz7"
      },
      "outputs": [],
      "source": [
        "# function to return recommended books - this will be tested\n",
        "def get_recommends(book = \"\"):\n",
        "    model_knn = NearestNeighbors(metric = 'cosine', n_neighbors=5, algorithm='auto')\n",
        "    model_knn.fit(book_features_df_matrix)\n",
        "\n",
        "    # found book TODO: user a better search\n",
        "    for query_index in range(len(book_features_df)):\n",
        "        if book_features_df.index[query_index] == book:\n",
        "            break\n",
        "\n",
        "    # creating return structure\n",
        "    ret = [book_features_df.index[query_index], []]\n",
        "    distances, indices = model_knn.kneighbors(book_features_df.iloc[query_index,:].values.reshape(1, -1))\n",
        "    # now we located the book. lets show the recomendations\n",
        "    for i in range(1, len(distances.flatten())):\n",
        "        ret[1].insert(0, [book_features_df.index[indices.flatten()[i]], distances.flatten()[i]])\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jd2SLCh8oxMh",
        "outputId": "6c6bd31e-8de5-4332-ebdd-4b23efe434ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Queen of the Damned (Vampire Chronicles (Paperback))', [['The Witching Hour (Lives of the Mayfair Witches)', 0.7371461], ['Taltos: Lives of the Mayfair Witches', 0.73265135], ['The Tale of the Body Thief (Vampire Chronicles (Paperback))', 0.5298544], ['The Vampire Lestat (Vampire Chronicles, Book II)', 0.51784116]]]\n",
            "You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\n"
          ]
        }
      ],
      "source": [
        "books = get_recommends(\"The Queen of the Damned (Vampire Chronicles (Paperback))\")\n",
        "print(books)\n",
        "\n",
        "def test_book_recommendation():\n",
        "  test_pass = True\n",
        "  recommends = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "  if recommends[0] != \"Where the Heart Is (Oprah's Book Club (Paperback))\":\n",
        "    test_pass = False\n",
        "  recommended_books = [\"I'll Be Seeing You\", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']\n",
        "  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]\n",
        "  for i in range(2): \n",
        "    if recommends[1][i][0] not in recommended_books:\n",
        "      test_pass = False\n",
        "    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:\n",
        "      test_pass = False\n",
        "  if test_pass:\n",
        "    print(\"You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying!\")\n",
        "\n",
        "test_book_recommendation()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "PkWCJdDDw0y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "_F3eogSmw1XZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_book_recommendation_knn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}